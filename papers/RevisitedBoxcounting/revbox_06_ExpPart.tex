\section {Experimental Part }

Revisited Box Counting technique will be tested on models of deterministic self-similar 2D fractal sets. They are generated by recursive expansion of binary matrix $\mathbb{G}_{u,v} \in \{ 0, 1 \}^{v \times v} $ where $u$ is number of nonzero elements (units), $v>1$ is matrix dimension, and $v<u<v^2$. \\
\\*
Recursive expansion of $\mathbb{G}_{u,v}$ generates binary matrix which represents fractal set $\mathbb{F}_{u,v}$ of similarity dimension $D_{\text{S}} = D_{\text{H}} = D_{0} = D_{1} = \frac{\log{u}}{\log{v}}$. Depth $h$ of recursion depends on $v$ and competer memory size.\\
\\*
Four testing sets: $\mathbb{F}_{3,2}$, $\mathbb{F}_{4,3}$, $\mathbb{F}_{5,3}$, $\mathbb{F}_{8,3}$ were generated by matrices:
\begin{itemize}
\item 

$\mathbb{G}_{3,2} = \begin{bmatrix}
1 & 1 \\
1 & 0 
\end{bmatrix}$ for $h=11$ 

\item 

$\mathbb{G}_{4,3} = \begin{bmatrix}
0 & 1 & 0 \\
1 & 0 & 1 \\
0 & 1 & 0
\end{bmatrix}$ for $h=7$

\item 

$\mathbb{G}_{5,3} = \begin{bmatrix}
0 & 1 & 0 \\
1 & 1 & 1 \\
0 & 1 & 0
\end{bmatrix}$ for $h=7$

\item 

$\mathbb{G}_{8,3} = \begin{bmatrix}
1 & 1 & 1 \\
1 & 0 & 1 \\
1 & 1 & 1
\end{bmatrix}$ for $h=7$
\end{itemize}
Sets $\mathbb{G}_{3,2}, \mathbb{G}_{8,3}$ corresponds to Sierpinski gasket and carpet. \\
\\*
Dimensions of $\mathbb{F}_{3,2}$, $\mathbb{F}_{4,3}$, $\mathbb{F}_{5,3}$, $\mathbb{F}_{8,3}$ are
\begin{equation} 
\label{eq:fracdim}
\begin{split}
\text{dim}(\mathbb{F}_{3,2}) & = \frac{\log{3}}{\log{2}} = 1.5850, \\
\text{dim}(\mathbb{F}_{4,3}) & = \frac{\log{4}}{\log{3}} = 1.2619, \\
\text{dim}(\mathbb{F}_{5,3}) & = \frac{\log{5}}{\log{3}} = 1.4650, \\
\text{dim}(\mathbb{F}_{8,3}) & = \frac{\log{8}}{\log{3}} = 1.8928.
\end{split}
\end{equation}
Agequate points sets with given depth $h$ were generated, first. Then, they were randomly rotated around origin and finally they were randomly shifted. After these operations the grid of size $a$ were put on the data points and entropy estimates were calculated. Due to physical interpretation of entropy, the estimates were averaged over 10 realizations and mean values of entropy were calculated. \\
\\*
Various estimates of Hartley entropy for grid size $a=2,3,4,...,30$ are depicted on Fig \ref{fig:frac}. Hartley entropy estimates are similar each other except underbiased naive estimate. Estimates $H_{0,\mbox{\scriptsize{BAYES}}}$ and $H_{0,\mbox{\scriptsize{low}}}$ are very similar in these four cases. Corresponding estimates of Shannon entropy are depicted on Fig. \ref{fig:fracshan} in the same range. \\
\\*
As seen in the Fig. \ref{fig:frac} and \ref{fig:fracshan}, too small grid size $a \leq 20$ comes to underestimation of $H_{0,\mbox{\scriptsize{naive}}}, H_{1,\mbox{\scriptsize{naive}}}$, but the other estimates are unfortunatelly overestimated. Therefore, revisited Box Counting was applied in the range $30 \leq a \leq 100$.\\
\\*
Using least square method we obtained various estimates of $D_{0}$ and $D_{1}$ and compared them with similarity dimension. Results of estimation are collected in Tabs. \ref{tab:est1} - \ref{tab:est4s}, where $\text{E}D$ is point estimate of given dimension, $s_{D}$ is its standard deviation, and $p_{\text{value}}$ is probability from t-test of hypothesis
\begin{equation} 
\label{eq:hypo}
\text{H}_{0} : \text{E}D = D_{\text{S}}
\end{equation}